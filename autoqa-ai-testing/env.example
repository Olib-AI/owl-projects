# =============================================================================
# AutoQA AI Testing - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values.
# All variables are optional unless marked (required).

# -----------------------------------------------------------------------------
# Browser Connection (required)
# -----------------------------------------------------------------------------
# Owl Browser remote instance URL and authentication token.
OWL_BROWSER_URL=https://your-browser-server.example.com
OWL_BROWSER_TOKEN=your-auth-token

# -----------------------------------------------------------------------------
# LLM Configuration (optional)
# -----------------------------------------------------------------------------
# Enable LLM-powered features (test name generation, vision analysis, etc.).
# All LLM features are opt-in and fall back gracefully when disabled.

AUTOQA_LLM_ENABLED=false

# OpenAI-compatible endpoint
AUTOQA_LLM_BASE_URL=https://api.openai.com/v1
AUTOQA_LLM_API_KEY=sk-your-api-key
AUTOQA_LLM_MODEL=gpt-4o-mini

# Provider: openai | azure | anthropic | local | custom
AUTOQA_LLM_PROVIDER=openai

# Request settings
AUTOQA_LLM_TEMPERATURE=0.3
AUTOQA_LLM_MAX_TOKENS=2048
AUTOQA_LLM_TIMEOUT_MS=30000

# Azure-specific (only when AUTOQA_LLM_PROVIDER=azure)
# AUTOQA_LLM_AZURE_DEPLOYMENT=your-deployment-name
# AUTOQA_LLM_AZURE_API_VERSION=2024-02-15-preview

# Vision capability override (auto-detected from model name by default)
# Set explicitly if your model supports vision but isn't auto-detected.
# AUTOQA_LLM_VISION_CAPABLE=true

# -----------------------------------------------------------------------------
# Per-Tool LLM Toggles
# -----------------------------------------------------------------------------
# Enable LLM for specific tools independently.

AUTOQA_LLM_TEST_BUILDER_ENABLED=false
AUTOQA_LLM_STEP_TRANSFORMER_ENABLED=false
AUTOQA_LLM_ASSERTIONS_ENABLED=false
AUTOQA_LLM_SELF_HEALING_ENABLED=false
AUTOQA_LLM_CHAOS_AGENTS_ENABLED=false

# Enable vision-based page analysis for the test builder.
# Requires a vision-capable model (GPT-4o, Claude 3/4, Gemini, GLM-4V, etc.).
AUTOQA_LLM_TEST_BUILDER_VISION=false

# -----------------------------------------------------------------------------
# Example: Local LM Studio with vision model
# -----------------------------------------------------------------------------
# AUTOQA_LLM_ENABLED=true
# AUTOQA_LLM_BASE_URL=http://127.0.0.1:1234/v1
# AUTOQA_LLM_MODEL=zai-org/glm-4.6v-flash
# AUTOQA_LLM_API_KEY=lm-studio
# AUTOQA_LLM_PROVIDER=custom
# AUTOQA_LLM_TIMEOUT_MS=120000
# AUTOQA_LLM_TEST_BUILDER_ENABLED=true
# AUTOQA_LLM_TEST_BUILDER_VISION=true

# -----------------------------------------------------------------------------
# Storage (optional)
# -----------------------------------------------------------------------------
# ARTIFACT_PATH=./artifacts

# S3-compatible storage for artifacts
# S3_ENDPOINT_URL=https://s3.amazonaws.com
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key
# AWS_REGION=us-east-1

# Database (optional)
# AUTOQA_DATABASE_URL=sqlite+aiosqlite:///autoqa.db

# Redis (optional, for distributed scheduling)
# AUTOQA_REDIS_URL=redis://localhost:6379/0
